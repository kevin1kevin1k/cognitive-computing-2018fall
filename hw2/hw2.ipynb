{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('.')\n",
    "dataset = p / 'dataset'\n",
    "features = p / 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_color_histogram_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix())\n",
    "\n",
    "    ub = 256\n",
    "    hist = np.concatenate([cv2.calcHist([img], [i], None, [ub], [0, ub])[:, 0] for i in range(3)])\n",
    "    hist /= hist.sum()\n",
    "    np.save(save_path, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_color_histogram_gray_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    ub = 256\n",
    "    hist = cv2.calcHist([img], [0], None, [ub], [0, ub])[:, 0]\n",
    "    hist /= hist.sum()\n",
    "    np.save(save_path, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regional_color_histogram_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix())\n",
    "\n",
    "    ub = 256\n",
    "    h, w, _ = img.shape\n",
    "    h //= 2\n",
    "    w //= 2\n",
    "    hists = []\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            region = img[h*i:h*(i+1), w*j:w*(j+1), :]\n",
    "            hist = np.concatenate([cv2.calcHist([region], [i], None, [ub], [0, ub])[:, 0] for i in range(3)])\n",
    "            hists.append(hist)\n",
    "    hist = np.concatenate(hists)\n",
    "    hist /= hist.sum()\n",
    "    np.save(save_path, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_nfeatures500_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix())\n",
    "    sift = cv2.xfeatures2d.SIFT_create(nfeatures=500)\n",
    "    _, des = sift.detectAndCompute(img, None)\n",
    "    np.save(save_path, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surf_hessianThreshold2000_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix())\n",
    "    surf = cv2.xfeatures2d.SURF_create(hessianThreshold=2000)\n",
    "    _, des = surf.detectAndCompute(img, None)\n",
    "    np.save(save_path, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix())\n",
    "    des = hog(img, orientations=8, pixels_per_cell=(img.shape[0] // 16, img.shape[1] // 16),\n",
    "              cells_per_block=(1, 1), block_norm='L2-Hys', multichannel=True)\n",
    "    np.save(save_path, des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_binary_pattern_save_feature(img_path, save_path):\n",
    "    img = cv2.imread(img_path.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
    "    radius = 2\n",
    "    n_points = 8 * radius\n",
    "    METHOD = 'uniform'\n",
    "    lbp = local_binary_pattern(img, n_points, radius, METHOD)\n",
    "    lbpi = np.uint8(lbp)\n",
    "    hist = cv2.calcHist([lbpi], [0], None, [n_points + 2], [0, n_points + 2])[:, 0]\n",
    "    hist /= hist.sum()\n",
    "    np.save(save_path, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name2func = {\n",
    "    'global_color_histogram': global_color_histogram_save_feature,\n",
    "    'global_color_histogram_gray': global_color_histogram_gray_save_feature,\n",
    "    'regional_color_histogram': regional_color_histogram_save_feature,\n",
    "    'sift_nfeatures500': sift_nfeatures500_save_feature,\n",
    "    'surf_hessianThreshold2000': surf_hessianThreshold2000_save_feature,\n",
    "    'local_binary_pattern': local_binary_pattern_save_feature,\n",
    "    'hog': hog_save_feature,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvd_covers done\n",
      "video_frames done\n",
      "business_cards done\n",
      "museum_paintings done\n",
      "cd_covers done\n",
      "book_covers done\n",
      "done\n",
      "CPU times: user 42min 16s, sys: 3min 59s, total: 46min 16s\n",
      "Wall time: 46min 16s\n"
     ]
    }
   ],
   "source": [
    "feature_name = 'hog'\n",
    "save_feature = feature_name2func[feature_name]\n",
    "for category in dataset.iterdir():\n",
    "    for typ in category.iterdir():\n",
    "        save_dir = features / feature_name / category.name / typ.name\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for img_path in typ.iterdir():\n",
    "            save_feature(img_path, save_dir / img_path.name)\n",
    "    print(category.name, 'done')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features/hog/dvd_covers/Reference\n",
      "features/hog/video_frames/Reference\n",
      "features/hog/business_cards/Reference\n",
      "features/hog/museum_paintings/Reference\n",
      "features/hog/cd_covers/Reference\n",
      "features/hog/book_covers/Reference\n"
     ]
    }
   ],
   "source": [
    "cat_num2id = dict()\n",
    "refs = []\n",
    "for category in (features / feature_name).iterdir():\n",
    "    ref = category / 'Reference'\n",
    "    print(ref)\n",
    "    for npy in ref.iterdir():\n",
    "        cat_num2id[category.name + npy.stem] = len(refs)\n",
    "        refs.append(np.float32(np.load(npy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_new(feature_dirname, method, descending=False):\n",
    "    for category in (features / feature_dirname).iterdir():\n",
    "        num_qrys = len(list(category.rglob('*npy')))\n",
    "        s_at_1 = 0\n",
    "        s_at_5 = 0\n",
    "        for typ in category.glob('[!R]*'):\n",
    "            for npy in typ.iterdir():\n",
    "                qry = np.float32(np.load(npy))\n",
    "                dists = [cv2.compareHist(qry, ref, method) for ref in refs]\n",
    "                indices = np.array(dists).argsort()\n",
    "                if descending:\n",
    "                    indices = indices[::-1]\n",
    "                top5 = indices[:5]\n",
    "                s_at_5 += cat_num2id[category.name + npy.stem] in top5\n",
    "                s_at_1 += cat_num2id[category.name + npy.stem] == top5[0]\n",
    "        print('{},{},{}'.format(category.name, s_at_1 / num_qrys, s_at_5 / num_qrys), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(cv2.HISTCMP_CORREL)\n",
    "print(cv2.HISTCMP_CHISQR) # good?\n",
    "print(cv2.HISTCMP_INTERSECT) # good?\n",
    "print(cv2.HISTCMP_BHATTACHARYYA)\n",
    "print(cv2.HISTCMP_CHISQR_ALT)\n",
    "descendings = [True, False, True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvd_covers,0.0,0.004,video_frames,0.064,0.118,business_cards,0.032,0.074,museum_paintings,0.041758241758241756,0.07032967032967033,cd_covers,0.01,0.026,book_covers,0.011881188118811881,0.033663366336633666,\n",
      "dvd_covers,0.0,0.0,video_frames,0.038,0.06,business_cards,0.002,0.008,museum_paintings,0.01098901098901099,0.05714285714285714,cd_covers,0.0,0.0,book_covers,0.0019801980198019802,0.007920792079207921,\n",
      "dvd_covers,0.0,0.0,video_frames,0.0,0.0,business_cards,0.0,0.0,museum_paintings,0.017582417582417582,0.046153846153846156,cd_covers,0.0,0.0,book_covers,0.0,0.0,\n",
      "dvd_covers,0.0,0.0,video_frames,0.002,0.002,business_cards,0.0,0.0,museum_paintings,0.008791208791208791,0.04835164835164835,cd_covers,0.0,0.0,book_covers,0.0019801980198019802,0.0019801980198019802,\n",
      "dvd_covers,0.0,0.0,video_frames,0.006,0.008,business_cards,0.0,0.0,museum_paintings,0.008791208791208791,0.05054945054945055,cd_covers,0.0,0.0,book_covers,0.0019801980198019802,0.0019801980198019802,\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    run_one_new('hog', i, descendings[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algo(create):\n",
    "    for i in range(1, 10):\n",
    "        img = cv2.imread((dataset / 'book_covers/5800/00{}.jpg'.format(i)).as_posix())\n",
    "        algo = create()\n",
    "        kp, des = algo.detectAndCompute(img, None)\n",
    "        print(img.shape, len(kp), des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features/surf_hessianThreshold2000/dvd_covers/Reference done\n",
      "features/surf_hessianThreshold2000/video_frames/Reference done\n",
      "features/surf_hessianThreshold2000/business_cards/Reference done\n",
      "features/surf_hessianThreshold2000/museum_paintings/Reference done\n",
      "features/surf_hessianThreshold2000/cd_covers/Reference done\n",
      "features/surf_hessianThreshold2000/book_covers/Reference done\n"
     ]
    }
   ],
   "source": [
    "cat_num2id = dict()\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_FLANNBASED)\n",
    "for category in (features / feature_name).iterdir():\n",
    "    ref = category / 'Reference'\n",
    "    for npy in ref.iterdir():\n",
    "        cat_num2id[category.name + npy.stem] = len(cat_num2id)\n",
    "        matcher.add([np.load(npy)])\n",
    "    print(ref, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_flann(feature_dirname):\n",
    "    for category in (features / feature_dirname).iterdir():\n",
    "        num_qrys = len(list(category.rglob('*npy')))\n",
    "        s_at_1 = 0\n",
    "        s_at_5 = 0\n",
    "        for typ in category.glob('[!R]*'):\n",
    "            for npy in typ.iterdir():\n",
    "                qry = np.load(npy)\n",
    "                try:\n",
    "                    matches = matcher.knnMatch(qry, k=2)\n",
    "                except:\n",
    "                    continue\n",
    "                ratio = 0.8\n",
    "                good_matches = [m1 for m1, m2 in matches if m1.distance < ratio * m2.distance]\n",
    "                if len(good_matches) == 0:\n",
    "                    good_matches = [m1 for m1, m2 in matches]\n",
    "                indices = np.bincount([m.imgIdx for m in good_matches]).argsort()[::-1]\n",
    "                top5 = indices[:5]\n",
    "                s_at_5 += cat_num2id[category.name + npy.stem] in top5\n",
    "                s_at_1 += cat_num2id[category.name + npy.stem] == top5[0]\n",
    "        print('{},{},{}'.format(category.name, s_at_1 / num_qrys, s_at_5 / num_qrys), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dvd_covers,0.75,0.776,video_frames,0.744,0.772,business_cards,0.522,0.594,museum_paintings,0.5340659340659341,0.5824175824175825,cd_covers,0.658,0.704,book_covers,0.6633663366336634,0.7425742574257426,\n",
      "CPU times: user 1min, sys: 128 ms, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "run_one_flann('surf_hessianThreshold2000')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
